{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa87e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_colors(cluster, centroids, exact=False):\n",
    "    \"\"\"for a given image, get all the colors and their percentages\"\"\"\n",
    "    # Get the number of different clusters, create histogram, and normalize\n",
    "    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(cluster.labels_, bins = labels)\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    \n",
    "    # Convert each RGB color code from float to int\n",
    "    if not exact:\n",
    "        centroids = centroids.astype(\"int\")\n",
    "    \n",
    "    # get the colors of the image\n",
    "    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n",
    "\n",
    "    return colors\n",
    "\n",
    "def is_dark(image):\n",
    "    \"\"\"cheks whether the dominant color of the image is dark\"\"\"\n",
    "    \n",
    "    #converts the image to a list of pixels\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    reshape = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    \n",
    "    # Find and display most X dominant colors\n",
    "    cluster = KMeans(n_clusters=5).fit(reshape)\n",
    "    colors = get_colors(cluster, cluster.cluster_centers_)\n",
    "    \n",
    "    # Obtain dominant RGB color code\n",
    "    dominant_color = colors[-1][1].tolist()\n",
    "    dominant_color_average = int(sum(dominant_color) / 3)\n",
    "    \n",
    "    # dominant_color_average <= 85: -> Dark/Black\n",
    "    # dominant_color_average > 85 and dominant_color_average <= 170 -> in between\n",
    "    # dominant_color_average > 170: Light/White\n",
    "    \n",
    "    #return dominant color\n",
    "    if dominant_color_average <= 85:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def inversion(img):\n",
    "    \"\"\"\n",
    "    if an image has light text on dark background,\n",
    "    inverts to get dark text on light background\n",
    "    \"\"\"\n",
    "    if is_dark(img):\n",
    "        return cv2.bitwise_not(img)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def super_res(img, path=\"/mnt/e/ADB_Project/github/adb-jobs-analysis/models/ESPCN_x3.pb\"):\n",
    "    \"\"\"increase the image resolution using OpenCV's ESPCN deep learning model\"\"\"\n",
    "    \n",
    "    #Load the Lapsrn model\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    sr.readModel(path)\n",
    "    sr.setModel(\"espcn\", 3)\n",
    "\n",
    "    #upsample and return the image\n",
    "    return sr.upsample(lwr1)\n",
    "\n",
    "def grayscale(img): #binarization_1\n",
    "    \"\"\"grayscaling images\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def blackwhite(gray_image): #binarization_2\n",
    "    \"\"\"making images black and white\"\"\"\n",
    "    thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)\n",
    "    return im_bw\n",
    "    \n",
    "def noise_removal(image): #feed im_bw\"\n",
    "    \"\"\"removes image noise\"\"\"\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return (image)\n",
    "\n",
    "def thin_font(image):\n",
    "    \"\"\"makes bold fonts thinner - known as erosion\"\"\"\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return image\n",
    "\n",
    "def thick_font(image):\n",
    "    \"\"\"makes faint fonts bolder - known as dilation\"\"\"\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return (image)\n",
    "\n",
    "def remove_borders(image):\n",
    "    \"\"\"removes borders from images\"\"\"\n",
    "    contours, heiarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))\n",
    "    cnt = cntsSorted[-1]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop = image[y:y+h, x:x+w]\n",
    "    return (crop)\n",
    "\n",
    "def add_borders(image):\n",
    "    \"\"\"expands the edges, incase the letters start too close to the edge\"\"\"\n",
    "    color = [255, 255, 255]\n",
    "    top, bottom, left, right = [250]*4\n",
    "    return cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "def main(img):\n",
    "    \"\"\"sequences the image preprocessing steps into a processing chain\"\"\"\n",
    "    \n",
    "    #invert\n",
    "    inverted = inversion(img)\n",
    "\n",
    "    #binarized\n",
    "    binarized = blackwhite(inverted)\n",
    "\n",
    "    #upscaled\n",
    "    upscaled = super_res(binarized)\n",
    "\n",
    "    #erosion\n",
    "    eroded = thick_font(upscaled)\n",
    "\n",
    "    #add_borders\n",
    "    bordered = add_borders(eroded)\n",
    "\n",
    "    return bordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8254b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946ddb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"E:\\ADB_Project\\github\\adb-jobs-analysis\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363e8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e272b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = \"E:/ADB_Project/data/cs_sample_ocr/602186.png\"\n",
    "img2 = \"E:/ADB_Project/data/cs_sample_ocr/\"\n",
    "img3 = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
